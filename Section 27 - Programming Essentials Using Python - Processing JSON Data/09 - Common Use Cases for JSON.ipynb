{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a88283f6",
   "metadata": {},
   "source": [
    "## Common Use Cases for JSON\n",
    "\n",
    "Here are some of the common use cases for JSON.\n",
    "\n",
    "   * Read data from JSON files.\n",
    "   * Write data to JSON files.\n",
    "   * We can use either `json` or `pandas` modules to read data from JSON files or write data to JSON files. One need to be familiar with both the approaches as each of them have different use cases and capabilities.\n",
    "   * Read JSON based response payloads on REST API Calls. We use `requests` module to process the REST API response Payloads.\n",
    "   * Once the payload is returned,, we can use appropriate modules to process the data further.\n",
    "\n",
    "## Read Data from JSON Files\n",
    "\n",
    "Here are the steps involved in reading data from JSON files.\n",
    "\n",
    "   * Using `json` module\n",
    "        * Create file object using `open` in read only mode.\n",
    "        * Pass the `file` object to `json.load`.\n",
    "        * `json.load` will return `dict`. We can process the data further using appropriate modules.\n",
    "   * Using `pandas` module.\n",
    "       * Use the path for the file to invoke `read_json`.\n",
    "       * A Pandas Data Frame will be created.\n",
    "       * We can process data further using rich APIs available in pandas module."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b41897b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using json module\n",
    "import json\n",
    "\n",
    "yt_file = open('youtube_playlist_items.json')\n",
    "yt_items = json.load(yt_file)\n",
    "\n",
    "type(yt_items)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d0757ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "yt_items.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62e22633",
   "metadata": {},
   "outputs": [],
   "source": [
    "yt_items['items']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58fc2755",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Further data processing (get video id and published time)\n",
    "list(map(lambda rec: rec['contentDetails'], yt_items))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37ab5c76",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using Pandas Module\n",
    "# As youtube items are part of nested json, we need to use both json and pandas\n",
    "import json\n",
    "import pandas as pd\n",
    "\n",
    "yt_file = open('youtube_playlist_items.json')\n",
    "yt_items = json.load(yt_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8de1b1bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "yt_items.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51ee8325",
   "metadata": {},
   "outputs": [],
   "source": [
    "yt_items"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32a694ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.json_normalize?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01c49f90",
   "metadata": {},
   "outputs": [],
   "source": [
    "yt_df = pd.json_normalize(yt_items, 'items')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fed8fdda",
   "metadata": {},
   "outputs": [],
   "source": [
    "yt_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd46b4e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "yt_df[['contentDetails.videoId', 'contentDetails.videoPublishedAt']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b66ce417",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using json to process customers data\n",
    "# We have one customer per line\n",
    "# We need to read the data as string then use json.loads to convert each string to dict.\n",
    "\n",
    "import json\n",
    "\n",
    "customers_file = open('customers.json')\n",
    "customers_list = customers_file.read().splitlines()\n",
    "\n",
    "# Converting the records in the file into list of dicts\n",
    "# We are processing each element in customers_list\n",
    "\n",
    "customers = list(mapÂ´(json.loads, customers_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3424dd69",
   "metadata": {},
   "outputs": [],
   "source": [
    "customers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b784ae8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using Pandas only to process customers data\n",
    "# For customers where we have one json per line, we can use Pandas directly\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "customers = pd.read_json('customers.json', lines=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a2b22cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "customers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4497791c",
   "metadata": {},
   "source": [
    "## Write Data to JSON Files\n",
    "\n",
    "Here are the steps involved in writing data to JSON files.\n",
    "\n",
    "   * Using `json` module.\n",
    "       * Make sure the `dict` object is ready with processed data as per requirements before writing to the file.\n",
    "       * Create file object using `open` in write mode.\n",
    "       * Pass the `file` object to `json.dump`.\n",
    "       * The `dict` will be dumped in the form of JSON in the fiel.\n",
    "   * Using `pandas` module.\n",
    "       * Make sure the Data Frame is ready with processed data as per requirements before writing to the file.\n",
    "       * Use the path for the file to invoke `to_json`. It can be invoked using Data Frame object which have the processed dara.\n",
    "       * The Pandas Data Frame will be written in the form of JSON in the fiel.\n",
    "       * We can leverage additional keyword arguments to control the behavior. For example `orient=records` can be used write the data frame the form of one JSON document per line. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
